<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <link rel="icon" href="data:;base64,iVBORw0KGgo=">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="./style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</title>
  <meta name="description"
    content="RUSplatting paper. Official web with qualitative comparisons, links to the source code, and additional materials.">
  <meta name="keywords" content="RUSplatting,3dgs,nerf,code" />
  <meta name="author" content="Zhuodong Jiang" />
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@3.7.0/dist/tabler-icons.min.css" rel="stylesheet">
</head>

<body>
  <header>
    <h1>
      <span class="title-main"><span>RUSplatting</span></span>
      <span class="title-small">Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</span>
    </h1>
    <div class="conference">BMVC 2025</div>
  </header>
  <div class="authors">
    <div class="author">
      <span class="author-name">Zhuodong Jiang</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Haoran Wang
      </span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Guoxi Huang</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Brett Seymour</span>
      <span class="author-affiliation">Submerged Resources Centre,<br> National Park Service</span>
    </div>
    <div class="author">
      <span class="author-name">Nantheera Anantrasirichai</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
  </div>
  <div class="links">
    <a class="button" href="./paper.pdf"><i class="ti ti-file-type-pdf"></i> Paper</a>
    <a class="button" href="https://arxiv.org/abs/2505.15737"><img
        style="height:80%;margin-right:0.2em;filter: brightness(0) saturate(100%) invert(100%)"
        src="./assets/arxiv.svg">
      arXiv</a>
    <a class="button" href="https://github.com/theflash987/RUSplatting"><i class="ti ti-brand-github-filled"></i>
      Code</a>
  </div>
  <style>
    .video.teaser-video::before {
      padding-bottom: 50%;
    }
  </style>
  <video class="video" style="aspect-ratio: 1920/1080" loop muted autoplay>
    <source src="./assets/curasao.webm" type="video/webm">
    <source src="./assets/curasao.mp4" type="video/mp4">
  </video>
  <p class="justify" style="font-size: 1rem;margin: 0 0 0.4rem 0; text-align-last: center">
    <strong>WaterSplatting</strong> combines 3DGS with volume rendering to enable water/fog modeling</strong>
  </p>

  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption,
      scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced
      Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep
      underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater
      attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve
      view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme.
      Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is
      essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured
      specifically in deep-sea environments. Experimental results demonstrate that our framework consistently
      outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality
      and robustness, and offering promising directions for marine robotics and underwater visual analytics.
    </p>
    <figure style="margin: 0">
      <img src="assets/overview.png" alt="RUSplatting overview" width="1600" height="900" loading="lazy"
        style="width: 100%; margin: 1em auto 0.3em; display: block;">
      <figcaption style="text-align: justify">
        Pipeline of RUSplatting. Yellow highlights indicate the proposed contributions:
        (1) colour-channel decoupling with a deeper MLP for improved estimation of underwater medium parameters;
        (2) IFI to enrich representations and enhance frame overlap;
        (3) an AFW strategy to suppress contributions from poorly interpolated frames;
        and (4) an ESL to reduce noise while preserving fine structural details.
      </figcaption>
    </figure>
  </section>
  <section>
    <h2>Results</h2>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/isro_uw_rus.webm" type="video/webm">
          <source src="./assets/isro_uw_rus.mp4" type="video/mp4">
        </video>
        <span class="video-label video-label-with-fps">
          <span>UW-GS</span>
          <span>RUSplatting</span>
        </span>
      </div>
      <figcaption>
        <strong>Isro - comparison with UW-GS</strong> <strong>Left:</strong>UW-GS<strong>
          Right:</strong> RUSplatting
      </figcaption>
    </figure>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/pana_uw_rus.webm" type="video/webm">
          <source src="./assets/pana_uw_rus.mp4" type="video/mp4">
        </video>
        <span class="video-label">
          <span>UW-GS</span>
          <span>RUSplatting</span>
        </span>
      </div>
      <figcaption>
        <strong>Panama - comparison with UW-GS</strong> <strong>Left:</strong>UW-GS<strong>Right:</strong>
        RUSplatting
      </figcaption>
    </figure>
  </section>
  <section>
    <h2>Acknowledgements</h2>
    <p class="justify">
      This work was supported by the UKRI MyWorld Strength in Places Programme(SIPF00006/1) and EPSRC ECR(EP/Y002490/1).
    </p>
  </section>
  <section class="citation">
    <h2>Citation</h2>
    <span>If you think this project is helpful, please feel free to leave a star or cite our paper:</span>
    <pre><code>@inproceedings{jiang2025rusplatting,
  author    = {Zhuodong Jiang and Haoran Wang and Guoxi Huang and Brett Seymour and Nantheera Anantrasirichai},
  title     = {RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction},
  booktitle = {Proceedings of the British Machine Vision Conference (BMVC)},
  year      = {2025}
}</code></pre>
  </section>
  <script src="./scripts.js"></script>
</body>

</html>