<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <link rel="icon" href="data:;base64,iVBORw0KGgo=">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="./style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</title>
  <meta name="description"
    content="RUSplatting paper. Official web with qualitative comparisons, links to the source code, and additional materials.">
  <meta name="keywords" content="RUSplatting,3dgs,nerf,code" />
  <meta name="author" content="Zhuodong Jiang" />
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@3.7.0/dist/tabler-icons.min.css" rel="stylesheet">
</head>

<body>
  <header>
    <h1>
      <span class="title-main"><span>RUSplatting</span></span>
      <span class="title-small">Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</span>
    </h1>
    <div class="conference">BMVC 2025</div>
  </header>
  <div class="authors-block">
    <p class="authors-line">
      <span class="author">Zhuodong Jiang<sup>1</sup></span>,
      <span class="author">Haoran Wang<sup>1</sup></span>,
      <span class="author">Guoxi Huang<sup>1</sup></span>,
      <span class="author">Brett Seymour<sup>2</sup></span>,
      <span class="author">Nantheera Anantrasirichai<sup>1</sup></span>
    </p>
    <div class="affils-list">
      <div><sup>1</sup> Visual Information Laboratory, University of Bristol, UK</div>
      <div><sup>2</sup> Submerged Resources Centre, National Park Service, USA</div>
    </div>
  </div>

  <div class="links">
    <a class="button" href="./paper.pdf"><i class="ti ti-file-type-pdf"></i> Paper</a>
    <a class="button" href="https://arxiv.org/abs/2505.15737"><img
        style="height:80%;margin-right:0.2em;filter: brightness(0) saturate(100%) invert(100%)"
        src="./assets/arxiv.svg">
      arXiv</a>
    <a class="button" href="https://github.com/theflash987/RUSplatting"><i class="ti ti-brand-github-filled"></i>
      Code</a>
    <a class="button" href="https://zenodo.org/records/15482420"><img
        style="height:80%;margin-right:0.2em;filter: brightness(0) saturate(100%) invert(100%)"
        src="./assets/dataset.svg">Dataset</a>
  </div>
  <style>
    .teaser-video {
      display: block;
      width: 100%;
      height: auto;
    }
  </style>
  <h2 class="teaser-title">Underwater Image Novel Views Rendering</h2>
  <video class="teaser-video" style="aspect-ratio: 16/9" loop muted autoplay playsinline>
    <source src="assets/isro_rus.webm" type="video/webm">
    <source src="assets/isro_rus.mp4" type="video/mp4">
  </video>
  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption,
      scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced
      Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep
      underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater
      attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve
      view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme.
      Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is
      essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured
      specifically in deep-sea environments. Experimental results demonstrate that our framework consistently
      outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality
      and robustness, and offering promising directions for marine robotics and underwater visual analytics.
    </p>
    <figure style="margin: 0">
      <img src="./assets/overview.svg" alt="RUSplatting overview" loading="lazy"
        style="width: 100%; height: auto; margin: 1em auto 0.3em; display: block;">
      <figcaption style="text-align: center">
        Pipeline of RUSplatting. Yellow highlights indicate the proposed contributions:
        (1) colour-channel decoupling with a deeper MLP for improved estimation of underwater medium parameters;
        (2) IFI to enrich representations and enhance frame overlap;
        (3) an AFW strategy to suppress contributions from poorly interpolated frames;
        and (4) an ESL to reduce noise while preserving fine structural details.
      </figcaption>
    </figure>
  </section>
  <section class="dataset">
    <h2>Dataset</h2>
    <p>
      Our newly collected dataset, Submerged3D. It consists of four scenes, each containing 20 RGB 720p images
      focusing on shipwrecks captured in the deep sea. It is challenging for 3D reconstruction due to sparse
      viewpoints and low-light environment conditions.
    </p>
    <figure style="margin: 0">
      <img src="./assets/examples.svg" alt="Dataset examples" loading="lazy"
        style="width: 100%; height: auto; margin: 1em auto 0.3em; display: block;">
      <figcaption style="text-align: center">
        Sample images from Submerged3D dataset.
      </figcaption>
    </figure>
  </section>
  <section>
    <h2>Results</h2>
    <figure>
      <h3 class="compare-title">Isro</h3>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/isro_uw_rus.webm" type="video/webm">
          <source src="./assets/isro_uw_rus.mp4" type="video/mp4">
        </video>
        <span class="video-label">
          <span>UW-GS</span>
          <span><strong>Ours</strong></span>
        </span>
      </div>
    </figure>
    <figure>
      <h3 class="compare-title">Panama</h3>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/pana_uw_rus.webm" type="video/webm">
          <source src="./assets/pana_uw_rus.mp4" type="video/mp4">
        </video>
        <span class="video-label">
          <span>UW-GS</span>
          <span><strong>Ours</strong></span>
        </span>
      </div>
    </figure>
  </section>
  <section>
    <h2>Acknowledgements</h2>
    <p class="justify">
      This work was supported by the UKRI MyWorld Strength in Places Programme(SIPF00006/1) and EPSRC ECR(EP/Y002490/1).
    </p>
  </section>
  <section class="citation">
    <h2>Citation</h2>
    <span>If you think this project is helpful, please feel free to leave a star or cite our paper:</span>
    <pre><code>@inproceedings{jiang2025rusplatting,
  author    = {Zhuodong Jiang and Haoran Wang and Guoxi Huang and Brett Seymour and Nantheera Anantrasirichai},
  title     = {RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction},
  booktitle = {Proceedings of the British Machine Vision Conference (BMVC)},
  year      = {2025}
}</code></pre>
  </section>
  <script src="./scripts.js"></script>
</body>

</html>