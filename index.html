<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <link rel="icon" href="data:;base64,iVBORw0KGgo=">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="./style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</title>
  <meta name="description"
    content="RUSplatting paper. Official web with qualitative comparisons, links to the source code, and additional materials.">
  <meta name="keywords" content="RUSplatting,3dgs,nerf,code" />
  <meta name="author" content="Zhuodong Jiang" />
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/@tabler/icons-webfont@3.7.0/dist/tabler-icons.min.css" rel="stylesheet">
</head>

<body>
  <header>
    <h1>
      <span class="title-main"><span>RUSplatting</span></span>
      <span class="title-small">Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction</span>
    </h1>
    <div class="conference">BMVC 2025</div>
  </header>
  <div class="authors">
    <div class="author">
      <span class="author-name">Zhuodong Jiang</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Haoran Wang
      </span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Guoxi Huang</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
    <div class="author">
      <span class="author-name">Brett Seymour</span>
      <span class="author-affiliation">Submerged Resources Centre,<br> National Park Service</span>
    </div>
    <div class="author">
      <span class="author-name">Nantheera Anantrasirichai</span>
      <span class="author-affiliation">Visual Information Laboratory,<br> University of Bristol</span>
    </div>
  </div>
  <div class="links">
    <a class="button" href="./paper.pdf"><i class="ti ti-file-type-pdf"></i> Paper</a>
    <a class="button" href="https://arxiv.org/abs/2505.15737"><img
        style="height:80%;margin-right:0.2em;filter: brightness(0) saturate(100%) invert(100%)"
        src="./assets/arxiv.svg">
      arXiv</a>
    <a class="button" href="https://github.com/theflash987/RUSplatting"><i class="ti ti-brand-github-filled"></i>
      Code</a>
  </div>
  <style>
    .video.teaser-video::before {
      padding-bottom: 50%;
    }
  </style>
  <video class="video" style="aspect-ratio: 1920/1080" loop muted autoplay>
    <source src="./assets/curasao.webm" type="video/webm">
    <source src="./assets/curasao.mp4" type="video/mp4">
  </video>
  <p class="justify" style="font-size: 1rem;margin: 0 0 0.4rem 0; text-align-last: center">
    <strong>WaterSplatting</strong> combines 3DGS with volume rendering to enable water/fog modeling</strong>
  </p>

  <section class="abstract">
    <h2>Abstract</h2>
    <p>
      Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption,
      scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced
      Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep
      underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater
      attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve
      view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme.
      Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is
      essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured
      specifically in deep-sea environments. Experimental results demonstrate that our framework consistently
      outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality
      and robustness, and offering promising directions for marine robotics and underwater visual analytics.
    </p>

    <figure style="margin: 0">
      <picture>
        <source srcset="./assets/overview.webp, /assets/overview@2x.webp 2x" type="image/webp" />
        <source srcset="./assets/overview.png, /assets/overview@2x.png 2x" type="image/png" />
        <img src="./assets/overview.png" alt="WaterSplatting overview"
          style="width: 100%; margin: 1em auto 0.3em auto; display: block;" />
      </picture>
      <figcaption style="text-align: justify">
        We start rendering by casting a ray per pixel and collect the patch-intersected Gaussians along the ray
        and their color given ray direction. Then, we walk through the list of sorted Gaussians per pixel, query their
        opacity and depth, based on
        which we acquire the transmittance of both Gaussians and medium, rendering the Gaussians and the segments
        between adjacent two to
        obtain the Medium component and the Object component.
      </figcaption>
    </figure>
  </section>
  <section>
    <h2>Results</h2>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/panama-seathru-ws.webm" type="video/webm">
          <source src="./assets/panama-seathru-ws.mp4" type="video/mp4">
        </video>
        <span class="video-label video-label-with-fps">
          <span>SeaThru-NeRF<div class="video-fps">FPS: 0.38</div></span>
          <span>WaterSplatting<div class="video-fps">FPS: 27.4</div></span>
        </span>
      </div>
      <figcaption>
        <strong>Panama - comparison with SeaThru-NeRF</strong> <strong>Left:</strong>SeaThru-NeRF<strong>
          Right:</strong> WaterSplatting.
      </figcaption>
    </figure>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/japan-seathru-ws.webm" type="video/webm">
          <source src="./assets/japan-seathru-ws.mp4" type="video/mp4">
        </video>
        <span class="video-label video-label-with-fps">
          <span>SeaThru-NeRF<div class="video-fps">FPS: 0.63</div></span>
          <span>WaterSplatting<div class="video-fps">FPS: 59.4</div></span>
        </span>
      </div>
      <figcaption>
        <strong>Japanese Gradens - comparison with SeaThru-NeRF</strong> <strong>Left:</strong>SeaThru-NeRF<strong>
          Right:</strong> WaterSplatting.
      </figcaption>
    </figure>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/iui3-obj.webm" type="video/webm">
          <source src="./assets/iui3-obj.mp4" type="video/mp4">
        </video>
        <span class="video-label">
          <span>WaterSplatting</span>
          <span>removed medium</span>
        </span>
      </div>
      <figcaption>
        <strong>IUI3 - w/o medium.</strong> <strong>Left:</strong>WaterSplatting reconstruction. <strong>Right:</strong>
        WaterSplatting with medium removed.
      </figcaption>
    </figure>
    <figure>
      <div class="video-wrapper">
        <video class="video-compare" style="aspect-ratio: 1280/720" loop muted>
          <source src="./assets/curasao-obj.webm" type="video/webm">
          <source src="./assets/curasao-obj.mp4" type="video/mp4">
        </video>
        <span class="video-label">
          <span>WaterSplatting</span>
          <span>removed medium</span>
        </span>
        <strong>Curasao - w/o medium.</strong> <strong>Left:</strong>WaterSplatting reconstruction.
        <strong>Right:</strong> WaterSplatting with medium removed.
        </span>
      </div>
    </figure>
  </section>
  <section>
    <h2>Acknowledgements</h2>
    <p class="justify">
      This work was supported by the UKRI MyWorld Strength in Places Programme(SIPF00006/1) and EPSRC ECR(EP/Y002490/1).
    </p>
  </section>
  <section class="citation">
    <h2>Citation</h2>
    <span>If you think this project is helpful, please feel free to leave a star or cite our paper:</span>
    <pre><code>@inproceedings{jiang2025rusplatting,
  author    = {Zhuodong Jiang and Haoran Wang and Guoxi Huang and Brett Seymour and Nantheera Anantrasirichai},
  title     = {RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction},
  booktitle = {Proceedings of the British Machine Vision Conference (BMVC)},
  year      = {2025}
}</code></pre>
  </section>
  <script src="./scripts.js"></script>
</body>

</html>